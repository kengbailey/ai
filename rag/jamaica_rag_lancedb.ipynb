{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers scikit-learn docx2txt datasets nltk lancedb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting openai\n",
      "  Downloading openai-1.35.10-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.11/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.11/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Downloading openai-1.35.10-py3-none-any.whl (328 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.3/328.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "Successfully installed openai-1.35.10\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence_transformers tf-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG from scratch w/ LanceDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article successfully written to article.txt\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "\n",
    "def get_wiki_article(title):\n",
    "    try:\n",
    "        page = wikipedia.page(title)\n",
    "        with open('jamaica.txt', 'w') as f:\n",
    "            f.write(page.content)\n",
    "        print(\"Article successfully written article to text\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "get_wiki_article('Jamaica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('jamaica.txt', 'r') as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Recursive Text Splitter\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "\n",
    "\n",
    "def recursive_text_splitter(text, max_chunk_length=1000, overlap=100):\n",
    "    \"\"\"\n",
    "    Helper function for chunking text recursively\n",
    "    \"\"\"\n",
    "    # Initialize result\n",
    "    result = []\n",
    "\n",
    "    current_chunk_count = 0\n",
    "    separator = [\"\\n\", \" \"]\n",
    "    _splits = re.split(f\"({separator})\", text)\n",
    "    splits = [_splits[i] + _splits[i + 1] for i in range(1, len(_splits), 2)]\n",
    "\n",
    "    for i in range(len(splits)):\n",
    "        if current_chunk_count != 0:\n",
    "            chunk = \"\".join(\n",
    "                splits[\n",
    "                    current_chunk_count\n",
    "                    - overlap : current_chunk_count\n",
    "                    + max_chunk_length\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            chunk = \"\".join(splits[0:max_chunk_length])\n",
    "\n",
    "        if len(chunk) > 0:\n",
    "            result.append(\"\".join(chunk))\n",
    "        current_chunk_count += max_chunk_length\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Chunks:  141\n"
     ]
    }
   ],
   "source": [
    "#split text\n",
    "\n",
    "chunks = recursive_text_splitter(text_data, max_chunk_length=100, overlap=10)\n",
    "print(\"Number of Chunks: \", len(chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Choose a pre-trained model (e.g., BERT, RoBERTa, etc.)\n",
    "# Load the tokenizer and model\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "def embedder(chunk):\n",
    "    \"\"\"\n",
    "    Helper function to embed chunk of text\n",
    "    \"\"\"\n",
    "    # Tokenize the input text\n",
    "    tokens = tokenizer(chunk, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    # Get the model's output (including embeddings)\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**tokens)\n",
    "\n",
    "    # Extract the embeddings\n",
    "    embeddings = model_output.last_hidden_state[:, 0, :]\n",
    "    embed = embeddings[0].numpy()\n",
    "    return embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed all the chunks of text\n",
    "embeds = []\n",
    "for chunk in chunks:\n",
    "    embed = embedder(chunks)\n",
    "    embeds.append(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "2024-07-04 18:29:21.011236: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-04 18:29:21.037131: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-04 18:29:21.495517: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "############ GPU Accelerated Embedding\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def embedder(chunks):    \n",
    "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return model.encode(chunks)\n",
    "\n",
    "embeds = embedder(chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert text chunks with their embeddings\n",
    "\n",
    "import lancedb\n",
    "\n",
    "\n",
    "def prepare_data(chunks, embeddings):\n",
    "    \"\"\"\n",
    "    Helper function to prepare data to insert in LanceDB\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for chunk, embed in zip(chunks, embeddings):\n",
    "        temp = {}\n",
    "        temp[\"text\"] = chunk\n",
    "        temp[\"vector\"] = embed\n",
    "        data.append(temp)\n",
    "    return data\n",
    "\n",
    "\n",
    "def lanceDBConnection(chunks, embeddings):\n",
    "    \"\"\"\n",
    "    LanceDB insertion\n",
    "    \"\"\"\n",
    "    db = lancedb.connect(\"lance.db\")\n",
    "    data = prepare_data(chunks, embeddings)\n",
    "    table = db.create_table(\n",
    "        \"scratch\",\n",
    "        data=data,\n",
    "        mode=\"overwrite\",\n",
    "    )\n",
    "    return table\n",
    "\n",
    "\n",
    "table = lanceDBConnection(chunks, embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval & Prompt Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever\n",
    "k = 5\n",
    "question = \"What is the jamaican motto\"\n",
    "\n",
    "# Embed Question\n",
    "query_embedding = embedder(question)\n",
    "# Semantic Search\n",
    "result = table.search(query_embedding).limit(5).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" Disney comedy Cool Runnings, which is loosely based on the true story of Jamaica's first bobsled team trying to make it in the Winter Olympics.\\n\\n\\n=== Cuisine ===\\n\\nThe island is famous for its Jamaican jerk spice, curries and rice and peas which is integral to Jamaican cuisine. Jamaica is also home to Red Stripe beer and Jamaican Blue Mountain Coffee.\\n\\n\\n=== National symbols ===\\n(From the Jamaica Information Service)\\n\\nNational bird: red-billed streamertail (also called doctor bird) (a hummingbird, Trochilus polytmus)\\nNational flower – lignum vitae (Guiacum officinale)\\nNational tree: blue mahoe (Hibiscus talipariti elatum)\\nNational fruit: ackee (Blighia\",\n",
       " ' Commonwealth realm, with Charles III as its king, the appointed representative of the Crown is the Governor-General of Jamaica, an office held by Patrick Allen since 2009.\\n\\n\\n== Etymology ==\\nThe indigenous people, the Taíno, called the island Xaymaca in their language, meaning the \"Land of Wood and Water\" or the \"Land of Springs\". Yamaye has been suggested as an early Taino name for the island as recorded by Christopher Columbus.\\nColloquially, Jamaicans refer to their home island as the \"Rock\". Slang names such as \"Jamrock\", \"Jamdown\" (\"Jamdung\" in Jamaican Patois), or briefly \"Ja\", have derived from this.',\n",
       " \"'s capital and largest city. Most Jamaicans are of Sub-Saharan African ancestry, with significant European, East Asian (primarily Chinese), Indian, Lebanese, and mixed-race minorities. Because of a high rate of emigration for work since the 1960s, there is a large Jamaican diaspora, particularly in Canada, the United Kingdom, and the United States. The country has a global influence that belies its small size; it was the birthplace of the Rastafari religion, reggae music (and such associated genres as dub, ska and dancehall), and it is internationally prominent in sports, including cricket, sprinting, and athletics. Jamaica\",\n",
       " ', Buffalo, the Miami metro area, Atlanta, Chicago, Orlando, Tampa, Washington, D.C., Philadelphia, Hartford, Providence and Los Angeles. In Canada, the Jamaican population is centred in Toronto, with smaller communities in cities such as Hamilton, Montreal, Winnipeg, Vancouver and Ottawa. Jamaican Canadians comprise about 30% of the entire Black Canadian population.\\nA notable though much smaller group of emigrants are Jamaicans in Ethiopia. These are mostly Rastafarians, in whose theological worldview Africa is the promised land, or \"Zion\", or more specifically Ethiopia, due to reverence in which former Ethiopian Emperor Haile',\n",
       " ' population, and destructive exploitation contribute to the decline of ocean and coastal resources. Developing practices that will contribute to the lives of the people but also to the life of the ocean and its ecosystem. Some of these practices include: Develop sustainable fisheries practices, ensure sustainable mariculture techniques and practices, sustainable management of shipping, and promote sustainable tourism practices.\\n\\n\\n== Demographics ==\\n\\n\\n=== Ethnic origins ===\\n\\nC.I.A. World Fact Book 2015\\n\\nJamaica\\'s diverse ethnic roots are reflected in the national motto \"Out of Many One People\". Most of the population of 2,812,000 (July 2018 est.) are of']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = [r[\"text\"] for r in result]\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context Prompt\n",
    "\n",
    "base_prompt = \"\"\"Your task is to understand the user question, and provide an answer using the provided contexts. Every answer you generate should have citations in this pattern  \"Answer [position].\", for example: \"Earth is round [1][2].,\" if it's relevant.\n",
    "\n",
    "Your answers are correct, high-quality, and written by an domain expert. If the provided context does not contain the answer, simply state, \"The provided context does not have the answer.\"\n",
    "\n",
    "User question: {}\n",
    "\n",
    "Contexts:\n",
    "{}\n",
    "\"\"\"\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Jamaican motto is \"Out of Many One People\" [5].\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# llm\n",
    "prompt = f\"{base_prompt.format(question, context)}\"\n",
    "\n",
    "client = OpenAI(api_key=\"sk-\")\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {'role': 'user', 'content': prompt, }\n",
    "    ],\n",
    "    model='gpt-4-turbo-2024-04-09',\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Jamaican motto is \"Out of Many One People\". [2] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# local Ollama \n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "prompt = f\"{base_prompt.format(question, context)}\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://192.168.8.116:11434/v1/',\n",
    "    api_key='ollama',\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {'role': 'user', 'content': prompt, }\n",
    "    ],\n",
    "    model='gemma2:9b-instruct-q5_K_M',\n",
    "    temperature=0,\n",
    ")\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI assistant. Your task is to understand the user question, and provide an answer using the provided contexts. Every answer you generate should have citations in this pattern  \"Answer [position].\", for example: \"Earth is round [1][2].,\" if it's relevant.\n",
      "\n",
      "Your answers are correct, high-quality, and written by an domain expert. If the provided context does not contain the answer, simply state, \"The provided context does not have the answer.\"\n",
      "\n",
      "User question: What is the jamaican motto\n",
      "\n",
      "Contexts:\n",
      "[\" Disney comedy Cool Runnings, which is loosely based on the true story of Jamaica's first bobsled team trying to make it in the Winter Olympics.\\n\\n\\n=== Cuisine ===\\n\\nThe island is famous for its Jamaican jerk spice, curries and rice and peas which is integral to Jamaican cuisine. Jamaica is also home to Red Stripe beer and Jamaican Blue Mountain Coffee.\\n\\n\\n=== National symbols ===\\n(From the Jamaica Information Service)\\n\\nNational bird: red-billed streamertail (also called doctor bird) (a hummingbird, Trochilus polytmus)\\nNational flower – lignum vitae (Guiacum officinale)\\nNational tree: blue mahoe (Hibiscus talipariti elatum)\\nNational fruit: ackee (Blighia\", ' Commonwealth realm, with Charles III as its king, the appointed representative of the Crown is the Governor-General of Jamaica, an office held by Patrick Allen since 2009.\\n\\n\\n== Etymology ==\\nThe indigenous people, the Taíno, called the island Xaymaca in their language, meaning the \"Land of Wood and Water\" or the \"Land of Springs\". Yamaye has been suggested as an early Taino name for the island as recorded by Christopher Columbus.\\nColloquially, Jamaicans refer to their home island as the \"Rock\". Slang names such as \"Jamrock\", \"Jamdown\" (\"Jamdung\" in Jamaican Patois), or briefly \"Ja\", have derived from this.', \"'s capital and largest city. Most Jamaicans are of Sub-Saharan African ancestry, with significant European, East Asian (primarily Chinese), Indian, Lebanese, and mixed-race minorities. Because of a high rate of emigration for work since the 1960s, there is a large Jamaican diaspora, particularly in Canada, the United Kingdom, and the United States. The country has a global influence that belies its small size; it was the birthplace of the Rastafari religion, reggae music (and such associated genres as dub, ska and dancehall), and it is internationally prominent in sports, including cricket, sprinting, and athletics. Jamaica\", ', Buffalo, the Miami metro area, Atlanta, Chicago, Orlando, Tampa, Washington, D.C., Philadelphia, Hartford, Providence and Los Angeles. In Canada, the Jamaican population is centred in Toronto, with smaller communities in cities such as Hamilton, Montreal, Winnipeg, Vancouver and Ottawa. Jamaican Canadians comprise about 30% of the entire Black Canadian population.\\nA notable though much smaller group of emigrants are Jamaicans in Ethiopia. These are mostly Rastafarians, in whose theological worldview Africa is the promised land, or \"Zion\", or more specifically Ethiopia, due to reverence in which former Ethiopian Emperor Haile', ' population, and destructive exploitation contribute to the decline of ocean and coastal resources. Developing practices that will contribute to the lives of the people but also to the life of the ocean and its ecosystem. Some of these practices include: Develop sustainable fisheries practices, ensure sustainable mariculture techniques and practices, sustainable management of shipping, and promote sustainable tourism practices.\\n\\n\\n== Demographics ==\\n\\n\\n=== Ethnic origins ===\\n\\nC.I.A. World Fact Book 2015\\n\\nJamaica\\'s diverse ethnic roots are reflected in the national motto \"Out of Many One People\". Most of the population of 2,812,000 (July 2018 est.) are of']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
